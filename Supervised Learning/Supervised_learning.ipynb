{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# conda install -c anaconda gensim\n",
    "import gensim\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import main file into a dataframe\n",
    "main_df = pd.read_csv('data/quora_duplicate_questions.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Google's pre-trained word2vec model\n",
    "#https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('model/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.07421875e-01  -2.01171875e-01   1.23046875e-01   2.11914062e-01\n",
      "  -9.13085938e-02   2.16796875e-01  -1.31835938e-01   8.30078125e-02\n",
      "   2.02148438e-01   4.78515625e-02   3.66210938e-02  -2.45361328e-02\n",
      "   2.39257812e-02  -1.60156250e-01  -2.61230469e-02   9.71679688e-02\n",
      "  -6.34765625e-02   1.84570312e-01   1.70898438e-01  -1.63085938e-01\n",
      "  -1.09375000e-01   1.49414062e-01  -4.65393066e-04   9.61914062e-02\n",
      "   1.68945312e-01   2.60925293e-03   8.93554688e-02   6.49414062e-02\n",
      "   3.56445312e-02  -6.93359375e-02  -1.46484375e-01  -1.21093750e-01\n",
      "  -2.27539062e-01   2.45361328e-02  -1.24511719e-01  -3.18359375e-01\n",
      "  -2.20703125e-01   1.30859375e-01   3.66210938e-02  -3.63769531e-02\n",
      "  -1.13281250e-01   1.95312500e-01   9.76562500e-02   1.26953125e-01\n",
      "   6.59179688e-02   6.93359375e-02   1.02539062e-02   1.75781250e-01\n",
      "  -1.68945312e-01   1.21307373e-03  -2.98828125e-01  -1.15234375e-01\n",
      "   5.66406250e-02  -1.77734375e-01  -2.08984375e-01   1.76757812e-01\n",
      "   2.38037109e-02  -2.57812500e-01  -4.46777344e-02   1.88476562e-01\n",
      "   5.51757812e-02   5.02929688e-02  -1.06933594e-01   1.89453125e-01\n",
      "  -1.16210938e-01   8.49609375e-02  -1.71875000e-01   2.45117188e-01\n",
      "  -1.73828125e-01  -8.30078125e-03   4.56542969e-02  -1.61132812e-02\n",
      "   1.86523438e-01  -6.05468750e-02  -4.17480469e-02   1.82617188e-01\n",
      "   2.20703125e-01  -1.22558594e-01  -2.55126953e-02  -3.08593750e-01\n",
      "   9.13085938e-02   1.60156250e-01   1.70898438e-01   1.19628906e-01\n",
      "   7.08007812e-02  -2.64892578e-02  -3.08837891e-02   4.06250000e-01\n",
      "  -1.01562500e-01   5.71289062e-02  -7.26318359e-03  -9.17968750e-02\n",
      "  -1.50390625e-01  -2.55859375e-01   2.16796875e-01  -3.63769531e-02\n",
      "   2.24609375e-01   8.00781250e-02   1.56250000e-01   5.27343750e-02\n",
      "   1.50390625e-01  -1.14746094e-01  -8.64257812e-02   1.19140625e-01\n",
      "  -7.17773438e-02   2.73437500e-01  -1.64062500e-01   7.29370117e-03\n",
      "   4.21875000e-01  -1.12792969e-01  -1.35742188e-01  -1.31835938e-01\n",
      "  -1.37695312e-01  -7.66601562e-02   6.25000000e-02   4.98046875e-02\n",
      "  -1.91406250e-01  -6.03027344e-02   2.27539062e-01   5.88378906e-02\n",
      "  -3.24218750e-01   5.41992188e-02  -1.35742188e-01   8.17871094e-03\n",
      "  -5.24902344e-02  -1.74713135e-03  -9.81445312e-02  -2.86865234e-02\n",
      "   3.61328125e-02   2.15820312e-01   5.98144531e-02  -3.08593750e-01\n",
      "  -2.27539062e-01   2.61718750e-01   9.86328125e-02  -5.07812500e-02\n",
      "   1.78222656e-02   1.31835938e-01  -5.35156250e-01  -1.81640625e-01\n",
      "   1.38671875e-01  -3.10546875e-01  -9.71679688e-02   1.31835938e-01\n",
      "  -1.16210938e-01   7.03125000e-02   2.85156250e-01   3.51562500e-02\n",
      "  -1.01562500e-01  -3.75976562e-02   1.41601562e-01   1.42578125e-01\n",
      "  -5.68847656e-02   2.65625000e-01  -2.09960938e-01   9.64355469e-03\n",
      "  -6.68945312e-02  -4.83398438e-02  -6.10351562e-02   2.45117188e-01\n",
      "  -9.66796875e-02   1.78222656e-02  -1.27929688e-01  -4.78515625e-02\n",
      "  -7.26318359e-03   1.79687500e-01   2.78320312e-02  -2.10937500e-01\n",
      "  -1.43554688e-01  -1.27929688e-01   1.73339844e-02  -3.60107422e-03\n",
      "  -2.04101562e-01   3.63159180e-03  -1.19628906e-01  -6.15234375e-02\n",
      "   5.93261719e-02  -3.23486328e-03  -1.70898438e-01  -3.14941406e-02\n",
      "  -8.88671875e-02  -2.89062500e-01   3.44238281e-02  -1.87500000e-01\n",
      "   2.94921875e-01   1.58203125e-01  -1.19628906e-01   7.61718750e-02\n",
      "   6.39648438e-02  -4.68750000e-02  -6.83593750e-02   1.21459961e-02\n",
      "  -1.44531250e-01   4.54101562e-02   3.68652344e-02   3.88671875e-01\n",
      "   1.45507812e-01  -2.55859375e-01  -4.46777344e-02  -1.33789062e-01\n",
      "  -1.38671875e-01   6.59179688e-02   1.37695312e-01   1.14746094e-01\n",
      "   2.03125000e-01  -4.78515625e-02   1.80664062e-02  -8.54492188e-02\n",
      "  -2.48046875e-01  -3.39843750e-01  -2.83203125e-02   1.05468750e-01\n",
      "  -2.14843750e-01  -8.74023438e-02   7.12890625e-02   1.87500000e-01\n",
      "  -1.12304688e-01   2.73437500e-01  -3.26171875e-01  -1.77734375e-01\n",
      "  -4.24804688e-02  -2.69531250e-01   6.64062500e-02  -6.88476562e-02\n",
      "  -1.99218750e-01  -7.03125000e-02  -2.43164062e-01  -3.66210938e-02\n",
      "  -7.37304688e-02  -1.77734375e-01   9.17968750e-02  -1.25000000e-01\n",
      "  -1.65039062e-01  -3.57421875e-01  -2.85156250e-01  -1.66992188e-01\n",
      "   1.97265625e-01  -1.53320312e-01   2.31933594e-02   2.06054688e-01\n",
      "   1.80664062e-01  -2.74658203e-02  -1.92382812e-01  -9.61914062e-02\n",
      "  -1.06811523e-02  -4.73632812e-02   6.54296875e-02  -1.25732422e-02\n",
      "   1.78222656e-02  -8.00781250e-02  -2.59765625e-01   9.37500000e-02\n",
      "  -7.81250000e-02   4.68750000e-02  -2.22167969e-02   1.86767578e-02\n",
      "   3.11279297e-02   1.04980469e-02  -1.69921875e-01   2.58789062e-02\n",
      "  -3.41796875e-02  -1.44042969e-02  -5.46875000e-02  -8.78906250e-02\n",
      "   1.96838379e-03   2.23632812e-01  -1.36718750e-01   1.75781250e-01\n",
      "  -1.63085938e-01   1.87500000e-01   3.44238281e-02  -5.63964844e-02\n",
      "  -2.27689743e-05   4.27246094e-02   5.81054688e-02  -1.07910156e-01\n",
      "  -3.88183594e-02  -2.69531250e-01   3.34472656e-02   9.81445312e-02\n",
      "   5.63964844e-02   2.23632812e-01  -5.49316406e-02   1.46484375e-01\n",
      "   5.93261719e-02  -2.19726562e-01   6.39648438e-02   1.66015625e-02\n",
      "   4.56542969e-02   3.26171875e-01  -3.80859375e-01   1.70898438e-01\n",
      "   5.66406250e-02  -1.04492188e-01   1.38671875e-01  -1.57226562e-01\n",
      "   3.23486328e-03  -4.80957031e-02  -2.48046875e-01  -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "#test our model on a random word\n",
    "test = model.wv['computer']\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "#get the feature length of word\n",
    "vec_len = len(test)\n",
    "print vec_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that takes a sentence as an argument, and returns a feature vector(300x1 array) out of it.\n",
    "We split the sentence into individual words, apply word2vec model on each of them, and take an average of all\n",
    "vectors, which represents the vector for our sentence.\"\"\"\n",
    "\n",
    "def sentence2vec(sentence):\n",
    "    # clean the punctuation marks from the sentence\n",
    "    clean_sentence = sentence.translate(None, string.punctuation)\n",
    "    # split the senctence into a list of words\n",
    "    word_list = clean_sentence.split()\n",
    "    # get number of words in sentence\n",
    "    sen_length = len(word_list)\n",
    "    # initialize the empty array that represens the sentence vector\n",
    "    sentence_vec_sum = [0]*300\n",
    "    # loop through the words\n",
    "    for word in word_list: \n",
    "        try: \n",
    "            # get the word vector from the pretrained model\n",
    "            word_vec = model.wv[word]\n",
    "            # \n",
    "            sentence_vec_sum[:] = [sentence_vec_sum[i] + word_vec[i] for i in xrange(len(sentence_vec_sum))]\n",
    "        except KeyError:\n",
    "            # this will happen when the word doesn't exist in the vocabulary of the original model. This typically\n",
    "            # includes stopwords, and we won't include them in our average\n",
    "            sen_length -= 1\n",
    "    \n",
    "    # since we need the average, we need to divide each element in the array by the size of the sentence\n",
    "    sentence_vec = [element / sen_length for element in sentence_vec_sum]\n",
    "   \n",
    "    \n",
    "    return sentence_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.056272066556490384,\n",
       " 0.031193659855769232,\n",
       " 0.041414701021634616,\n",
       " 0.008253831129807692,\n",
       " -0.058158287635216348,\n",
       " -0.017897385817307692,\n",
       " 0.044771634615384616,\n",
       " -0.16353665865384615,\n",
       " 0.058265099158653848,\n",
       " 0.080697866586538464,\n",
       " -0.063157301682692304,\n",
       " -0.05690354567307692,\n",
       " 0.063218336838942304,\n",
       " 0.037184495192307696,\n",
       " -0.11766242980957031,\n",
       " 0.051584097055288464,\n",
       " 0.010779747596153846,\n",
       " 0.099346454326923073,\n",
       " -0.0057091346153846151,\n",
       " -0.054086538461538464,\n",
       " 0.039355351374699518,\n",
       " 0.063739483173076927,\n",
       " -6.5730168269230766e-05,\n",
       " -0.055944002591646634,\n",
       " 0.026181147648737982,\n",
       " 0.060575045072115384,\n",
       " -0.079450167142427891,\n",
       " 0.092998798076923073,\n",
       " 0.0120086669921875,\n",
       " 0.02837195763221154,\n",
       " -0.0087479811448317301,\n",
       " -0.044987605168269232,\n",
       " -0.10189115084134616,\n",
       " 0.044205885667067304,\n",
       " -0.042015662560096152,\n",
       " 0.01223285381610577,\n",
       " -0.057448167067307696,\n",
       " 0.002422626201923077,\n",
       " 0.11459585336538461,\n",
       " 0.071176382211538464,\n",
       " 0.016981858473557692,\n",
       " 0.023888221153846152,\n",
       " 0.065157376802884609,\n",
       " 0.026573768028846152,\n",
       " -0.01427166278545673,\n",
       " -0.064184335561899036,\n",
       " -0.053999680739182696,\n",
       " 0.020057091346153848,\n",
       " -0.036564753605769232,\n",
       " 0.06155043381911058,\n",
       " 0.01898193359375,\n",
       " 0.090965857872596159,\n",
       " 0.019061748798076924,\n",
       " -0.092904897836538464,\n",
       " 0.04197340745192308,\n",
       " -0.02448096642127404,\n",
       " -0.0286865234375,\n",
       " -0.11066847581129807,\n",
       " 0.066315871018629804,\n",
       " -0.055870643028846152,\n",
       " -0.086567805363581732,\n",
       " 0.012521597055288462,\n",
       " -0.077561598557692304,\n",
       " -0.036405123197115384,\n",
       " -0.024503267728365384,\n",
       " -0.076256385216346159,\n",
       " -0.016495191133939303,\n",
       " 0.038386418269230768,\n",
       " 0.021012526292067308,\n",
       " 0.071702223557692304,\n",
       " -0.086388221153846159,\n",
       " -0.0095778245192307699,\n",
       " 0.062819260817307696,\n",
       " -0.000213623046875,\n",
       " -0.031728891225961536,\n",
       " -0.046384371243990384,\n",
       " 0.067420372596153841,\n",
       " 0.090979942908653841,\n",
       " 0.0020282451923076925,\n",
       " 0.12980299729567307,\n",
       " -0.01531688983623798,\n",
       " -0.05561476487379808,\n",
       " 0.0748291015625,\n",
       " -0.014629657451923076,\n",
       " 0.02021965613731971,\n",
       " 0.00064380352313701925,\n",
       " -0.056969275841346152,\n",
       " 0.030048076923076924,\n",
       " 0.05271559495192308,\n",
       " 0.028354351337139424,\n",
       " 0.16713303786057693,\n",
       " 0.017784705528846152,\n",
       " -0.051195584810697116,\n",
       " -0.091139573317307696,\n",
       " 0.05219679612379808,\n",
       " -0.07159423828125,\n",
       " -0.033609243539663464,\n",
       " 0.01830115685096154,\n",
       " 0.04981642503004808,\n",
       " 0.002324030949519231,\n",
       " -0.04141367398775541,\n",
       " -0.021409254807692308,\n",
       " -0.054518479567307696,\n",
       " 0.052241398737980768,\n",
       " -0.035142164963942304,\n",
       " -0.03782301682692308,\n",
       " -0.054246168870192304,\n",
       " -0.00238037109375,\n",
       " -0.00093900240384615387,\n",
       " -0.030545748197115384,\n",
       " -0.011629544771634616,\n",
       " -0.007042518028846154,\n",
       " -0.038771409254807696,\n",
       " 0.020532754751352165,\n",
       " 0.076472355769230768,\n",
       " 0.055335411658653848,\n",
       " 0.0066434420072115381,\n",
       " -0.04804640549879808,\n",
       " 0.10970012958233173,\n",
       " 0.0284423828125,\n",
       " 0.01287841796875,\n",
       " 0.035062349759615384,\n",
       " -0.15469125600961539,\n",
       " 0.031686636117788464,\n",
       " -0.031306340144230768,\n",
       " -0.0220947265625,\n",
       " -0.0244140625,\n",
       " -0.055199256310096152,\n",
       " 0.044743464543269232,\n",
       " 0.068866436298076927,\n",
       " -0.043610792893629804,\n",
       " -0.02940955528846154,\n",
       " -0.0087714562049278841,\n",
       " 0.042414738581730768,\n",
       " 0.091536301832932696,\n",
       " -0.061739408052884616,\n",
       " -0.017329289362980768,\n",
       " -0.00060096153846153849,\n",
       " -0.04005784254807692,\n",
       " 0.076850304236778841,\n",
       " 0.12359149639423077,\n",
       " -0.060800405649038464,\n",
       " -0.03580885667067308,\n",
       " 0.043846717247596152,\n",
       " 0.00080402080829326925,\n",
       " -0.053955078125,\n",
       " 0.078636756310096159,\n",
       " -0.065503927377554089,\n",
       " 0.032307551457331732,\n",
       " -0.049654447115384616,\n",
       " 0.05059814453125,\n",
       " -0.061661940354567304,\n",
       " -0.030972994290865384,\n",
       " 0.036806546724759616,\n",
       " -0.03789109450120192,\n",
       " -0.044846754807692304,\n",
       " -0.044954153207632214,\n",
       " -0.079655573918269232,\n",
       " -0.025742750901442308,\n",
       " -0.010489830603966346,\n",
       " 0.032498873197115384,\n",
       " 0.025026761568509616,\n",
       " -0.011316739595853366,\n",
       " -0.015812800480769232,\n",
       " -0.013070913461538462,\n",
       " -0.056570199819711536,\n",
       " 0.081681471604567304,\n",
       " -0.038945124699519232,\n",
       " 0.035893366887019232,\n",
       " -0.030860314002403848,\n",
       " -0.16054124098557693,\n",
       " -0.070237379807692304,\n",
       " -0.003971980168269231,\n",
       " -0.1218731219951923,\n",
       " -0.003245427058293269,\n",
       " -0.03663987379807692,\n",
       " 0.095834585336538464,\n",
       " -0.081242487980769232,\n",
       " 0.017071063701923076,\n",
       " -0.02767005333533654,\n",
       " -0.14774263822115385,\n",
       " -0.095457810621995196,\n",
       " -0.060307429387019232,\n",
       " -0.042809119591346152,\n",
       " -0.0038780799278846155,\n",
       " -0.016357421875,\n",
       " -0.005074134239783654,\n",
       " 0.11065673828125,\n",
       " 0.082801231971153841,\n",
       " 0.038050724909855768,\n",
       " 0.015117938701923076,\n",
       " 0.029864971454326924,\n",
       " 0.0082350510817307699,\n",
       " -0.042292668269230768,\n",
       " -0.10870830829326923,\n",
       " -0.010161179762620192,\n",
       " -0.074343167818509609,\n",
       " 0.0020540677584134615,\n",
       " 0.022395207331730768,\n",
       " -0.14019305889423078,\n",
       " -0.077974759615384609,\n",
       " 0.018648587740384616,\n",
       " 0.0054837740384615381,\n",
       " 0.018841083233173076,\n",
       " -0.12628643329326922,\n",
       " 0.010178786057692308,\n",
       " -0.0035682091346153845,\n",
       " -0.086341271033653841,\n",
       " 0.054513784555288464,\n",
       " -0.04709977370042067,\n",
       " 0.007643479567307692,\n",
       " 0.12437086838942307,\n",
       " -0.088756854717548073,\n",
       " 0.064816988431490391,\n",
       " -0.14204758864182693,\n",
       " 0.083919818584735573,\n",
       " 0.18028846153846154,\n",
       " -0.015742375300480768,\n",
       " -0.034254807692307696,\n",
       " -0.026188777043269232,\n",
       " -0.025803786057692308,\n",
       " -0.028254582331730768,\n",
       " -0.038580380953275241,\n",
       " -0.01153094951923077,\n",
       " 0.0096341646634615381,\n",
       " -0.02918830284705529,\n",
       " 0.023587740384615384,\n",
       " -0.062269944411057696,\n",
       " 0.04235487717848558,\n",
       " 0.012169471153846154,\n",
       " -0.0362548828125,\n",
       " -0.079420823317307696,\n",
       " 0.056546724759615384,\n",
       " 0.05156296950120192,\n",
       " 0.022219731257512018,\n",
       " 0.006188025841346154,\n",
       " -0.021715604341947116,\n",
       " 0.008460411658653846,\n",
       " -0.030104417067307692,\n",
       " 0.039679894080528848,\n",
       " -0.0035611666165865385,\n",
       " -0.025191086989182692,\n",
       " 0.009803185096153846,\n",
       " -0.028517503004807692,\n",
       " 0.1053466796875,\n",
       " -0.031832181490384616,\n",
       " 0.038198617788461536,\n",
       " 0.063542292668269232,\n",
       " 0.028569148137019232,\n",
       " -0.072462815504807696,\n",
       " 0.05592698317307692,\n",
       " 0.011549729567307692,\n",
       " 0.017061673677884616,\n",
       " 0.063507666954627409,\n",
       " 0.048457219050480768,\n",
       " -0.034644493689903848,\n",
       " 0.023822490985576924,\n",
       " 0.026465782752403848,\n",
       " -0.080904447115384609,\n",
       " -0.05796461838942308,\n",
       " 0.016038161057692308,\n",
       " -0.038691594050480768,\n",
       " 0.035508375901442304,\n",
       " 0.044210580679086536,\n",
       " 0.1010296161358173,\n",
       " 0.12847430889423078,\n",
       " -0.007213885967548077,\n",
       " -0.024686373197115384,\n",
       " -0.083158052884615391,\n",
       " -0.025148831881009616,\n",
       " 0.010479266826923076,\n",
       " 0.14208045372596154,\n",
       " 0.059037428635817304,\n",
       " 0.026982234074519232,\n",
       " 0.053156926081730768,\n",
       " -0.0010610727163461538,\n",
       " -0.040189302884615384,\n",
       " -0.067570612980769232,\n",
       " -0.097017728365384609,\n",
       " -0.005803034855769231,\n",
       " 0.070105919471153841,\n",
       " -0.06051283616286058,\n",
       " 0.023770845853365384,\n",
       " 0.11691988431490384,\n",
       " 0.05583543043870192,\n",
       " 0.05155592698317308,\n",
       " -0.10060471754807693,\n",
       " -0.025775615985576924,\n",
       " -0.05125075120192308,\n",
       " 0.017230694110576924,\n",
       " -0.14154522235576922,\n",
       " 0.075373722956730768,\n",
       " -0.070974496694711536,\n",
       " -0.01212017352764423,\n",
       " -0.035606971153846152,\n",
       " -0.023817795973557692,\n",
       " -0.0035400390625,\n",
       " 0.050058218149038464,\n",
       " 0.043184720552884616,\n",
       " -0.03770094651442308]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"\"\"What is the step by step guide to invest in; share! market, in. india?\"\"\"\n",
    "sentence2vec(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the step by step guide to invest in share market?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the first row from the dataframe \n",
    "main_df.loc[0].values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a function to parse dataframe into np array\n",
    "\"\"\"Function that takes a df row as an argument and converts into two np array rows\"\"\"\n",
    "def df_to_np(df_row):\n",
    "    # vector from sentence 1\n",
    "    try:\n",
    "        vec_1 = sentence2vec(df_row[3])\n",
    "    except ZeroDivisionError:\n",
    "        vec_1 = [0]*300\n",
    "    # vector from sentence 2\n",
    "    try:\n",
    "        vec_2 = sentence2vec(df_row[4])\n",
    "    except ZeroDivisionError:\n",
    "        vec_2 = [0]*300\n",
    "    # absolute difference between the vectors\n",
    "    row_vec = [abs(x-y) for x,y in zip(vec_1, vec_2)]\n",
    "    # get the is_duplicate out of the array\n",
    "    is_dupe = df_row[5]\n",
    "    \n",
    "    return row_vec, is_dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thejaswi\\Anaconda2\\lib\\site-packages\\gensim\\models\\keyedvectors.py:444: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if word in self.vocab:\n"
     ]
    }
   ],
   "source": [
    "# Initialize np arrays\n",
    "data_size = 10000\n",
    "X = np.zeros((data_size,300))\n",
    "Y = np.zeros((data_size,1))\n",
    "x = np.zeros((data_size,300))\n",
    "y = np.zeros((data_size,1))\n",
    "\n",
    "# Traverse the dataframe and add the results into the relevant numpy arrays\n",
    "for i in xrange(data_size):\n",
    "    row_vec, is_dupe = df_to_np(main_df.loc[i])\n",
    "    X[i] = row_vec\n",
    "    Y[i] = is_dupe\n",
    "for i in xrange(int(0.6*data_size)):\n",
    "    x[i] = X[i]\n",
    "    y[i] = Y[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thejaswi\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time for some ML play!\n",
    "\n",
    "# Initialize the model\n",
    "clf = svm.SVC()\n",
    "# Train it on the dataset\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74449\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X[int(0.6*data_size):data_size][:])\n",
    "y_test = Y[int(0.6*data_size):data_size]\n",
    "print accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19629331/python-how-to-find-accuracy-result-in-svm-text-classifier-algorithm-for-multil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
